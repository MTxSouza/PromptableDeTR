# *The embedding_dim must be 512 for all models to match the MobileBert embedding 
# size. The MobileBert model will be used as an encoder for text data, and this 
# embedding will be used during cross-attention with the image embedding.
[model]
    image_size = 640
    text_context_window = 512
    vocab_size = 30522
    embedding_dim = 128
    embedding_proj_dim = 512
    embedding_dropout = 0.1
    num_heads = 8
    feed_forward_dim = 2048
    num_joiner_layers = 3


[training]

    [aligner]
        batch_size = 64
        learning_rate_curve = ""
        learning_rate = 0.0001
        max_iterations = 250000
        eval_interval = 1000
        weight_decay = 0.0
        exp_dir = "./exp"

    [detector]
        batch_size = 32
        learning_rate_curve = ""
        learning_rate = 0.00001
        max_iterations = 10000
        eval_interval = 100
        weight_decay = 0.0
        exp_dir = "./exp"
        bbox_loss_weight = 5.0
        obj_loss_weight = 2.0
